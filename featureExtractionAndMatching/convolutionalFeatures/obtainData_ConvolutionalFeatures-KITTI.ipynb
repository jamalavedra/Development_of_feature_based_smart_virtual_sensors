{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USqqj59bGftX",
        "colab_type": "text"
      },
      "source": [
        "# import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQeai4CkGfta",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "602866cb-8165-4470-fb80-6cb726ab1282"
      },
      "source": [
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "!pip install pykitti\n",
        "import pykitti\n",
        "import cv2\n",
        "from matplotlib.patches import Circle\n",
        "import csv\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import sys\n",
        "!pip install torchvision\n",
        "import sys\n",
        "!{sys.executable} -m pip install torchsummary\n",
        "!{sys.executable} -m pip install pytorchvis\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "!pip install pytorchvis\n",
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "from pytorchvis.visualize_layers import VisualizeLayers\n",
        "from PIL import Image as PImage\n",
        "import io\n",
        "import math\n",
        "from scipy.spatial import distance as dist\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pykitti\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/7e/e2b71b9221ccb8503dce9673e3cb36edcdc314ec374f9e69e6d38ed1abde/pykitti-0.3.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from pykitti) (3.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pykitti) (1.0.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from pykitti) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pykitti) (1.18.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pykitti) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pykitti) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pykitti) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pykitti) (1.2.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pykitti) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->pykitti) (1.12.0)\n",
            "Installing collected packages: pykitti\n",
            "Successfully installed pykitti-0.3.1\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: torch==1.5.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.5.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0->torchvision) (0.16.0)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "Collecting pytorchvis\n",
            "  Downloading https://files.pythonhosted.org/packages/9f/ce/bd41fdd56288465d7081bce6c9b458adb0a5696a032c9633f4241684fafd/pytorchvis-0.0.4-py3-none-any.whl\n",
            "Installing collected packages: pytorchvis\n",
            "Successfully installed pytorchvis-0.0.4\n",
            "Requirement already satisfied: pytorchvis in /usr/local/lib/python3.6/dist-packages (0.0.4)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLdzF8JjGftt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "63e2192b-4eac-48fb-a40e-785f4a7f46e0"
      },
      "source": [
        "# Run on Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POkFRgEMGft3",
        "colab_type": "text"
      },
      "source": [
        "## Load Kitti dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUHccuqTGft5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Path to KITTI directory\n",
        "basedir = '/content/drive/2011_09_26_drive_0001_sync'\n",
        "date = '2011_09_26'\n",
        "drive = '0001'\n",
        "\n",
        "dataset = pykitti.raw(basedir, date, drive)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI1SCLpOGfuE",
        "colab_type": "text"
      },
      "source": [
        "## Camera displacement utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDj0P6v1GfuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def latToScale(lat):\n",
        "# compute mercator scale from latitude\n",
        "    return math.cos(lat * math.pi / 180)\n",
        "\n",
        "def latlonToMercator(lat,lon,scale):\n",
        "# converts lat/lon coordinates to mercator coordinates using mercator scale\n",
        "    er = 6378137 # earth radius\n",
        "    mx = scale * lon * math.pi * er / 180\n",
        "    my = scale * er * math.log( math.tan((90+lat) * math.pi / 360) )\n",
        "    return mx, my\n",
        "\n",
        "def convertOxtsToPose(oxts):\n",
        "    scale = latToScale(oxts[0][0])\n",
        "    pose = []\n",
        "    Tr_0_inv = np.zeros(shape=(4,4))\n",
        "    Tr = np.zeros(shape=(4,4))\n",
        "    t = np.zeros(shape=(3, 1))\n",
        "    for i in range(len(oxts)):\n",
        "        if not oxts[i]:\n",
        "            pose.append([])\n",
        "            continue\n",
        "\n",
        "        # translation vector \n",
        "        t[0,0], t[1,0] = latlonToMercator(oxts[i][0],oxts[i][1],scale)\n",
        "        t[2,0] = oxts[i][2]\n",
        "\n",
        "        # rotation matrix (OXTS RT3000 user manual, page 71/92)\n",
        "        rx = oxts[i][3] # roll\n",
        "        ry = oxts[i][4] # pitch\n",
        "        rz = oxts[i][5] # heading \n",
        "        # base => nav  (level oxts => rotated oxts)\n",
        "        Rx = np.matrix([[1, 0, 0], [0, math.cos(rx), -math.sin(rx)], [0, math.sin(rx), math.cos(rx)]]) \n",
        "        # base => nav  (level oxts => rotated oxts)\n",
        "        Ry =  np.matrix([[math.cos(ry), 0, math.sin(ry)], [0, 1, 0], [-math.sin(ry), 0, math.cos(ry)]]) \n",
        "        # base => nav  (level oxts => rotated oxts)\n",
        "        Rz = np.matrix([[math.cos(rz), -math.sin(rz), 0], [math.sin(rz), math.cos(rz), 0], [0, 0, 1]]) \n",
        "        R  = Rz*Ry*Rx\n",
        "\n",
        "        # print(R)\n",
        "        # print(t)\n",
        "        Tr[:3, :3] = R\n",
        "        Tr[:3, 3:] = t\n",
        "        Tr[3,3] = 1\n",
        "        # normalize translation and rotation (start at 0/0/0)\n",
        "        if i == 0:\n",
        "            Tr_0_inv = np.linalg.inv(Tr)\n",
        "\n",
        "        pose.append((Tr_0_inv.dot(Tr)))\n",
        "    return np.stack(pose)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiA55KxfGfuT",
        "colab_type": "text"
      },
      "source": [
        "## Velodyne in Camera utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfDMMl1SGfuU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://stackoverflow.com/questions/45333780/kitti-velodyne-point-to-pixel-coordinate\n",
        "def prepare_velo_points(pts3d_raw):\n",
        "    '''Replaces the reflectance value by 1, and tranposes the array, so\n",
        "       points can be directly multiplied by the camera projection matrix'''\n",
        "\n",
        "    pts3d = pts3d_raw\n",
        "    # Reflectance > 0\n",
        "    pts3d = pts3d[pts3d[:, 3] > 0 ,:]\n",
        "    pts3d[:,3] = 1\n",
        "    return pts3d.transpose()\n",
        "\n",
        "def project_velo_points_in_img(pts3d, T_cam_velo, Rrect, Prect):\n",
        "    '''Project 3D points into 2D image. Expects pts3d as a 4xN\n",
        "       numpy array. Returns the 2D projection of the points that\n",
        "       are in front of the camera only an the corresponding 3D points.'''\n",
        "\n",
        "    # 3D points in camera reference frame.\n",
        "    pts3d_cam = Rrect.dot(T_cam_velo.dot(pts3d))\n",
        "\n",
        "    # Before projecting, keep only points with z>0 \n",
        "    # (points that are in fronto of the camera).\n",
        "    idx = (pts3d_cam[2,:]>=0)\n",
        "    pts2d_cam = Prect.dot(pts3d_cam[:,idx])\n",
        "    return pts3d[:, idx], pts2d_cam/pts2d_cam[2,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9Ir6-_6Gfud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "5bba306fadd24d7cbcf47b85eed56190",
            "a3e2ce67e33042edad7acfe12b56e213",
            "63f62925001c41eb9cb7cd245ee6ada6",
            "dc893e72907743fa94d894e3fdbe4082",
            "d0a67eeb51314f57a24ab4e193395046",
            "2e6471f2762a4470b2bcd84a62623cd5",
            "8b1107d8d742453ba0cba8585b197618",
            "f9eaedc4a918419ba0918040a26679b4"
          ]
        },
        "outputId": "98dedcf8-3d02-49f6-8340-d0a355fd92f0"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.vgg16(pretrained=True).to(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5bba306fadd24d7cbcf47b85eed56190",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZglcFmAGful",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "row_list = [[\"x_displacement\", \"y_displacement\", \"sensors_x\", \"sensors_y\", \"sensors_d\", \"sensors_e\", \"coordinates_src\", \"depth_src\",\"coordinates_dst\", \"depth_dst\"]]\n",
        "\n",
        "normalize = transforms.Normalize(\n",
        "   mean=[0.485, 0.456, 0.406],\n",
        "   std=[0.229, 0.224, 0.225]\n",
        ")\n",
        "preprocess = transforms.Compose([\n",
        "   transforms.Resize([224, 224]),\n",
        "   transforms.ToTensor(),\n",
        "   normalize\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dWzwPcOYBaXr"
      },
      "source": [
        "## Convolutional features utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ2sI45FGfus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pairwise_distance(X, Y):\n",
        "    assert len(X.shape) == len(Y.shape)\n",
        "    N = X.shape[0]\n",
        "    M = Y.shape[0]\n",
        "    # D = len(X.shape)\n",
        "    res = np.zeros([M, N])\n",
        "    for i in range(M):\n",
        "        for j in range(N):\n",
        "            res[i][j] = np.linalg.norm(X[j] - Y[i])\n",
        "    return res\n",
        "\n",
        "def match(PD):\n",
        "    seq = np.arange(PD.shape[0]) # create array of a certain shape from 0 to len\n",
        "    amin1 = np.argmin(PD, axis=1) # return smallest index from each list\n",
        "    C = np.array([seq, amin1]).transpose()\n",
        "    min1 = PD[seq, amin1] # array of the minimum distances\n",
        "    mask = np.zeros_like(PD) # return an array of zeros of the same shape as DP\n",
        "    mask[seq, amin1] = 1\n",
        "    masked = np.ma.masked_array(PD, mask) # PD without the smallest values\n",
        "    min2 = np.amin(masked, axis=1) # return smallest num in list\n",
        "    return C, np.array(min2/min1)\n",
        "\n",
        "def match_max(PD):\n",
        "    seq = np.arange(PD.shape[0])\n",
        "    amax1 = np.argmin(PD, axis=1)\n",
        "    C = np.array([seq, amax1]).transpose()\n",
        "    return C"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ln_XdWUGfu2",
        "colab_type": "text"
      },
      "source": [
        "## Features with depth utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPRfZq1GGfu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find2perCent(num, listPro):\n",
        "    listfeatures = []\n",
        "    Menys = 0.98 * num\n",
        "    Mes = 1.02 * num \n",
        "    for i, el in enumerate(listPro):\n",
        "        if el < Mes and el > Menys:\n",
        "            listfeatures.append(i)\n",
        "    return listfeatures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VXK5lKbm3Z6l"
      },
      "source": [
        "## Main loop\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keAVOXl_Gfu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oxts = []\n",
        "for pos in dataset.oxts:\n",
        "    oxt = [i for i in pos[0]]\n",
        "    oxts.append(oxt)\n",
        "\n",
        "camera_displacement = []\n",
        "pose = convertOxtsToPose(oxts)\n",
        "l = 3 # coordinate axis length\n",
        "A = np.array([[0, 0, 0, 1], [l, 0, 0, 1], [0, 0, 0, 1], [0, l, 0, 1], [0, 0, 0, 1], [0, 0, l, 1]]).transpose()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ],
        "id": "s68qTP6VGfvG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36b94b66-0f55-4c4e-8269-33000a160a1c"
      },
      "source": [
        "index = 0\n",
        "frames = 5\n",
        "depth = False\n",
        "for j, cam3 in enumerate(dataset.cam3):\n",
        "    B = pose[j].dot(A)\n",
        "    pts3d = prepare_velo_points(dataset.get_velo(j))\n",
        "    if j == 0:\n",
        "        IX = cam3.convert('RGB')\n",
        "        IX_trand = preprocess(IX)\n",
        "        IX_trand.unsqueeze_(0)\n",
        "        sizeX = np.array(IX).shape[1]\n",
        "        sizeY = np.array(IX).shape[0]\n",
        "        camScale = np.array(IX.size[:2]) / np.array([224.0, 224.0])\n",
        "        camScale = camScale[::-1]\n",
        "        projectionX = project_velo_points_in_img(pts3d, dataset.calib.T_cam3_velo, dataset.calib.R_rect_30,dataset.calib.P_rect_30)\n",
        "\n",
        "    elif j%frames ==0:\n",
        "        projectionY = project_velo_points_in_img(pts3d, dataset.calib.T_cam3_velo, dataset.calib.R_rect_30,dataset.calib.P_rect_30)\n",
        "        IY_trand = preprocess(cam3.convert('RGB'))\n",
        "        IY_trand.unsqueeze_(0)\n",
        "\n",
        "        cnn_input = torch.cat((IX_trand, IY_trand), dim=0)\n",
        "        vis = VisualizeLayers(model,layers='all')\n",
        "        output = model(cnn_input.to(device))\n",
        "        # get the intermediate layers output which was passed d  uring initialization\n",
        "        interm_output = vis.get_interm_output()\n",
        "        features_pool3 = interm_output['features.16_pooling_MaxPool2d'].cpu()\n",
        "        \n",
        "        \n",
        "        featureMap = []\n",
        "        DY1 = np.zeros(shape=(784,256))\n",
        "        pool3_flat = np.reshape(features_pool3[1], [-1, 784]).numpy()\n",
        "        for i in range(pool3_flat.shape[1]):\n",
        "            for kernel in pool3_flat:\n",
        "                featureMap.append(kernel[i])\n",
        "            DY1[i] = featureMap\n",
        "            featureMap = []\n",
        "\n",
        "        DX1 = np.zeros(shape=(784,256))\n",
        "        pool3_flat = np.reshape(features_pool3[0], [-1, 784]).numpy()\n",
        "        for i in range(pool3_flat.shape[1]):\n",
        "            for kernel in pool3_flat:\n",
        "                featureMap.append(kernel[i])\n",
        "            DX1[i] = featureMap\n",
        "            featureMap = []\n",
        "        \n",
        "        PD1 = pairwise_distance(DX1, DY1)\n",
        "        seq = np.array([[i, j] for i in range(28)\n",
        "                    for j in range(28)], dtype='int32')\n",
        "\n",
        "        X = np.array(seq, dtype='float32') * 8.0 + 4.0\n",
        "        Y = np.array(seq, dtype='float32') * 8.0 + 4.0\n",
        "\n",
        "        # prematch and select points\n",
        "        C_all, quality = match(PD1)\n",
        "        theta_max = np.max(quality) # large starting threshold that only confident inliers satisfy\n",
        "        while np.where(quality >= theta_max)[0].shape[0] <= 128:\n",
        "            theta_max -= 0.01\n",
        "        C = C_all[np.where(quality >= theta_max)]\n",
        "        X, Y = X[C[:, 1]], Y[C[:, 0]]\n",
        "        # num_matches = C.shape[0]\n",
        "        Xscaled = X * camScale\n",
        "        Yscaled = Y * camScale\n",
        "        if depth: \n",
        "            featureWithDepthX = np.zeros(shape=(Xscaled.shape[0], Xscaled.shape[1] +2), dtype=np.float64)\n",
        "            featureWithDepthY = np.zeros(shape=(Yscaled.shape[0], Yscaled.shape[1] +2), dtype=np.float64)\n",
        "\n",
        "            projectionX_roundedX = [round(i, 1) for i in projectionX[1][0]]\n",
        "            projectionX_roundedY = [round(i, 1) for i in projectionX[1][1]]\n",
        "            projectionY_roundedX = [round(i, 1) for i in projectionY[1][0]]\n",
        "            projectionY_roundedY = [round(i, 1) for i in projectionY[1][1]]\n",
        "\n",
        "            for i, feature in enumerate(Xscaled):\n",
        "                listindX =find2perCent(round(feature[1], 1), projectionX_roundedX)\n",
        "                listindY =find2perCent(round(feature[0], 1), projectionX_roundedY)\n",
        "                if len(listindY) > 0 and len(listindX) > 0:\n",
        "                    cand = set(listindX).intersection(listindY) # detect coordindates \n",
        "                    if len(cand)>0:\n",
        "                        featureWithDepthX[i] = np.append(feature, [True, projectionX[0][0][cand.pop()]])\n",
        "\n",
        "            for i, feature in enumerate(Yscaled):\n",
        "                listindX =find2perCent(round(feature[1], 1), projectionY_roundedX)\n",
        "                listindY =find2perCent(round(feature[0], 1), projectionY_roundedY)\n",
        "                if len(listindY) > 0 and len(listindX) > 0:\n",
        "                    cand = set(listindX).intersection(listindY) # detect coordindates \n",
        "                    if len(cand)>0:\n",
        "                        featureWithDepthY[i] = np.append(feature, [True, projectionY[0][0][cand.pop()]])\n",
        "        else:\n",
        "            featureWithDepthX = Xscaled\n",
        "            featureWithDepthY = Yscaled\n",
        "\n",
        "        difference_listX = []\n",
        "        difference_listY = []\n",
        "        difference_listZ = []\n",
        "        euclideanDistance_list = []\n",
        "\n",
        "        coordinatesSRC = []\n",
        "        coordinatesDST = []\n",
        "        depthListSRC = []\n",
        "        depthListDST = []\n",
        "\n",
        "        for i, pnt in enumerate(featureWithDepthX):\n",
        "            if depth:\n",
        "                if pnt[2] == True and featureWithDepthY[i][2] == True:\n",
        "                    src_x = (pnt[1])\n",
        "                    src_y = (pnt[0])\n",
        "                    dst_x = (featureWithDepthY[i][1])\n",
        "                    dst_y = (featureWithDepthY[i][0])\n",
        "\n",
        "                    difference_listX.append(src_x - dst_x)\n",
        "                    difference_listY.append(src_y - dst_y)\n",
        "                    difference_listZ.append(featureWithDepthX[i][3] - featureWithDepthY[i][3])\n",
        "                    euclideanDistance_list.append(dist.euclidean((src_x, src_y), (dst_x, dst_y)))\n",
        "\n",
        "                    coordinatesSRC.append(src_x/sizeX)\n",
        "                    coordinatesSRC.append(src_y/sizeY)\n",
        "                    depthListSRC.append(featureWithDepthX[i][3])\n",
        "\n",
        "                    coordinatesDST.append(dst_x/sizeX)\n",
        "                    coordinatesDST.append(dst_y/sizeY)\n",
        "                    depthListDST.append(featureWithDepthY[i][3])\n",
        "\n",
        "            else:\n",
        "                src_x = (pnt[1])\n",
        "                src_y = (pnt[0])\n",
        "                dst_x = (featureWithDepthY[i][1])\n",
        "                dst_y = (featureWithDepthY[i][0])\n",
        "\n",
        "                difference_listX.append(src_x - dst_x)\n",
        "                difference_listY.append(src_y - dst_y)\n",
        "                euclideanDistance_list.append(dist.euclidean((src_x, src_y), (dst_x, dst_y)))\n",
        "\n",
        "                depthListSRC.append(1)\n",
        "                coordinatesSRC.append(src_x/sizeX)\n",
        "                coordinatesSRC.append(src_y/sizeY)\n",
        "\n",
        "                depthListDST.append(1)\n",
        "                coordinatesDST.append(dst_x/sizeX)\n",
        "                coordinatesDST.append(dst_y/sizeY)\n",
        "\n",
        "        x_displacement = B[0,0:2][0] - pose[j-frames].dot(A)[0,0:2][0]\n",
        "        y_displacement = B[1,2:4][0] - pose[j-frames].dot(A)[1,2:4][0]\n",
        "        index +=1\n",
        "        \n",
        "        row_list.append([x_displacement, y_displacement, difference_listX, difference_listY,difference_listZ, euclideanDistance_list, coordinatesSRC, depthListSRC, coordinatesDST, depthListDST])\n",
        "\n",
        "        IX_trand = IY_trand\n",
        "        projectionX = projectionY"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "features_container_Sequential\n",
            "\t features.0_conv_Conv2d\n",
            "\t features.1_activation_ReLU\n",
            "\t features.2_conv_Conv2d\n",
            "\t features.3_activation_ReLU\n",
            "\t features.4_pooling_MaxPool2d\n",
            "\t features.5_conv_Conv2d\n",
            "\t features.6_activation_ReLU\n",
            "\t features.7_conv_Conv2d\n",
            "\t features.8_activation_ReLU\n",
            "\t features.9_pooling_MaxPool2d\n",
            "\t features.10_conv_Conv2d\n",
            "\t features.11_activation_ReLU\n",
            "\t features.12_conv_Conv2d\n",
            "\t features.13_activation_ReLU\n",
            "\t features.14_conv_Conv2d\n",
            "\t features.15_activation_ReLU\n",
            "\t features.16_pooling_MaxPool2d\n",
            "\t features.17_conv_Conv2d\n",
            "\t features.18_activation_ReLU\n",
            "\t features.19_conv_Conv2d\n",
            "\t features.20_activation_ReLU\n",
            "\t features.21_conv_Conv2d\n",
            "\t features.22_activation_ReLU\n",
            "\t features.23_pooling_MaxPool2d\n",
            "\t features.24_conv_Conv2d\n",
            "\t features.25_activation_ReLU\n",
            "\t features.26_conv_Conv2d\n",
            "\t features.27_activation_ReLU\n",
            "\t features.28_conv_Conv2d\n",
            "\t features.29_activation_ReLU\n",
            "\t features.30_pooling_MaxPool2d\n",
            "avgpool_pooling_AdaptiveAvgPool2d\n",
            "classifier_container_Sequential\n",
            "\t classifier.0_linear_Linear\n",
            "\t classifier.1_activation_ReLU\n",
            "\t classifier.2_dropout_Dropout\n",
            "\t classifier.3_linear_Linear\n",
            "\t classifier.4_activation_ReLU\n",
            "\t classifier.5_dropout_Dropout\n",
            "\t classifier.6_linear_Linear\n",
            "features_container_Sequential\n",
            "\t features.0_conv_Conv2d\n",
            "\t features.1_activation_ReLU\n",
            "\t features.2_conv_Conv2d\n",
            "\t features.3_activation_ReLU\n",
            "\t features.4_pooling_MaxPool2d\n",
            "\t features.5_conv_Conv2d\n",
            "\t features.6_activation_ReLU\n",
            "\t features.7_conv_Conv2d\n",
            "\t features.8_activation_ReLU\n",
            "\t features.9_pooling_MaxPool2d\n",
            "\t features.10_conv_Conv2d\n",
            "\t features.11_activation_ReLU\n",
            "\t features.12_conv_Conv2d\n",
            "\t features.13_activation_ReLU\n",
            "\t features.14_conv_Conv2d\n",
            "\t features.15_activation_ReLU\n",
            "\t features.16_pooling_MaxPool2d\n",
            "\t features.17_conv_Conv2d\n",
            "\t features.18_activation_ReLU\n",
            "\t features.19_conv_Conv2d\n",
            "\t features.20_activation_ReLU\n",
            "\t features.21_conv_Conv2d\n",
            "\t features.22_activation_ReLU\n",
            "\t features.23_pooling_MaxPool2d\n",
            "\t features.24_conv_Conv2d\n",
            "\t features.25_activation_ReLU\n",
            "\t features.26_conv_Conv2d\n",
            "\t features.27_activation_ReLU\n",
            "\t features.28_conv_Conv2d\n",
            "\t features.29_activation_ReLU\n",
            "\t features.30_pooling_MaxPool2d\n",
            "avgpool_pooling_AdaptiveAvgPool2d\n",
            "classifier_container_Sequential\n",
            "\t classifier.0_linear_Linear\n",
            "\t classifier.1_activation_ReLU\n",
            "\t classifier.2_dropout_Dropout\n",
            "\t classifier.3_linear_Linear\n",
            "\t classifier.4_activation_ReLU\n",
            "\t classifier.5_dropout_Dropout\n",
            "\t classifier.6_linear_Linear\n",
            "features_container_Sequential\n",
            "\t features.0_conv_Conv2d\n",
            "\t features.1_activation_ReLU\n",
            "\t features.2_conv_Conv2d\n",
            "\t features.3_activation_ReLU\n",
            "\t features.4_pooling_MaxPool2d\n",
            "\t features.5_conv_Conv2d\n",
            "\t features.6_activation_ReLU\n",
            "\t features.7_conv_Conv2d\n",
            "\t features.8_activation_ReLU\n",
            "\t features.9_pooling_MaxPool2d\n",
            "\t features.10_conv_Conv2d\n",
            "\t features.11_activation_ReLU\n",
            "\t features.12_conv_Conv2d\n",
            "\t features.13_activation_ReLU\n",
            "\t features.14_conv_Conv2d\n",
            "\t features.15_activation_ReLU\n",
            "\t features.16_pooling_MaxPool2d\n",
            "\t features.17_conv_Conv2d\n",
            "\t features.18_activation_ReLU\n",
            "\t features.19_conv_Conv2d\n",
            "\t features.20_activation_ReLU\n",
            "\t features.21_conv_Conv2d\n",
            "\t features.22_activation_ReLU\n",
            "\t features.23_pooling_MaxPool2d\n",
            "\t features.24_conv_Conv2d\n",
            "\t features.25_activation_ReLU\n",
            "\t features.26_conv_Conv2d\n",
            "\t features.27_activation_ReLU\n",
            "\t features.28_conv_Conv2d\n",
            "\t features.29_activation_ReLU\n",
            "\t features.30_pooling_MaxPool2d\n",
            "avgpool_pooling_AdaptiveAvgPool2d\n",
            "classifier_container_Sequential\n",
            "\t classifier.0_linear_Linear\n",
            "\t classifier.1_activation_ReLU\n",
            "\t classifier.2_dropout_Dropout\n",
            "\t classifier.3_linear_Linear\n",
            "\t classifier.4_activation_ReLU\n",
            "\t classifier.5_dropout_Dropout\n",
            "\t classifier.6_linear_Linear\n",
            "features_container_Sequential\n",
            "\t features.0_conv_Conv2d\n",
            "\t features.1_activation_ReLU\n",
            "\t features.2_conv_Conv2d\n",
            "\t features.3_activation_ReLU\n",
            "\t features.4_pooling_MaxPool2d\n",
            "\t features.5_conv_Conv2d\n",
            "\t features.6_activation_ReLU\n",
            "\t features.7_conv_Conv2d\n",
            "\t features.8_activation_ReLU\n",
            "\t features.9_pooling_MaxPool2d\n",
            "\t features.10_conv_Conv2d\n",
            "\t features.11_activation_ReLU\n",
            "\t features.12_conv_Conv2d\n",
            "\t features.13_activation_ReLU\n",
            "\t features.14_conv_Conv2d\n",
            "\t features.15_activation_ReLU\n",
            "\t features.16_pooling_MaxPool2d\n",
            "\t features.17_conv_Conv2d\n",
            "\t features.18_activation_ReLU\n",
            "\t features.19_conv_Conv2d\n",
            "\t features.20_activation_ReLU\n",
            "\t features.21_conv_Conv2d\n",
            "\t features.22_activation_ReLU\n",
            "\t features.23_pooling_MaxPool2d\n",
            "\t features.24_conv_Conv2d\n",
            "\t features.25_activation_ReLU\n",
            "\t features.26_conv_Conv2d\n",
            "\t features.27_activation_ReLU\n",
            "\t features.28_conv_Conv2d\n",
            "\t features.29_activation_ReLU\n",
            "\t features.30_pooling_MaxPool2d\n",
            "avgpool_pooling_AdaptiveAvgPool2d\n",
            "classifier_container_Sequential\n",
            "\t classifier.0_linear_Linear\n",
            "\t classifier.1_activation_ReLU\n",
            "\t classifier.2_dropout_Dropout\n",
            "\t classifier.3_linear_Linear\n",
            "\t classifier.4_activation_ReLU\n",
            "\t classifier.5_dropout_Dropout\n",
            "\t classifier.6_linear_Linear\n",
            "features_container_Sequential\n",
            "\t features.0_conv_Conv2d\n",
            "\t features.1_activation_ReLU\n",
            "\t features.2_conv_Conv2d\n",
            "\t features.3_activation_ReLU\n",
            "\t features.4_pooling_MaxPool2d\n",
            "\t features.5_conv_Conv2d\n",
            "\t features.6_activation_ReLU\n",
            "\t features.7_conv_Conv2d\n",
            "\t features.8_activation_ReLU\n",
            "\t features.9_pooling_MaxPool2d\n",
            "\t features.10_conv_Conv2d\n",
            "\t features.11_activation_ReLU\n",
            "\t features.12_conv_Conv2d\n",
            "\t features.13_activation_ReLU\n",
            "\t features.14_conv_Conv2d\n",
            "\t features.15_activation_ReLU\n",
            "\t features.16_pooling_MaxPool2d\n",
            "\t features.17_conv_Conv2d\n",
            "\t features.18_activation_ReLU\n",
            "\t features.19_conv_Conv2d\n",
            "\t features.20_activation_ReLU\n",
            "\t features.21_conv_Conv2d\n",
            "\t features.22_activation_ReLU\n",
            "\t features.23_pooling_MaxPool2d\n",
            "\t features.24_conv_Conv2d\n",
            "\t features.25_activation_ReLU\n",
            "\t features.26_conv_Conv2d\n",
            "\t features.27_activation_ReLU\n",
            "\t features.28_conv_Conv2d\n",
            "\t features.29_activation_ReLU\n",
            "\t features.30_pooling_MaxPool2d\n",
            "avgpool_pooling_AdaptiveAvgPool2d\n",
            "classifier_container_Sequential\n",
            "\t classifier.0_linear_Linear\n",
            "\t classifier.1_activation_ReLU\n",
            "\t classifier.2_dropout_Dropout\n",
            "\t classifier.3_linear_Linear\n",
            "\t classifier.4_activation_ReLU\n",
            "\t classifier.5_dropout_Dropout\n",
            "\t classifier.6_linear_Linear\n",
            "features_container_Sequential\n",
            "\t features.0_conv_Conv2d\n",
            "\t features.1_activation_ReLU\n",
            "\t features.2_conv_Conv2d\n",
            "\t features.3_activation_ReLU\n",
            "\t features.4_pooling_MaxPool2d\n",
            "\t features.5_conv_Conv2d\n",
            "\t features.6_activation_ReLU\n",
            "\t features.7_conv_Conv2d\n",
            "\t features.8_activation_ReLU\n",
            "\t features.9_pooling_MaxPool2d\n",
            "\t features.10_conv_Conv2d\n",
            "\t features.11_activation_ReLU\n",
            "\t features.12_conv_Conv2d\n",
            "\t features.13_activation_ReLU\n",
            "\t features.14_conv_Conv2d\n",
            "\t features.15_activation_ReLU\n",
            "\t features.16_pooling_MaxPool2d\n",
            "\t features.17_conv_Conv2d\n",
            "\t features.18_activation_ReLU\n",
            "\t features.19_conv_Conv2d\n",
            "\t features.20_activation_ReLU\n",
            "\t features.21_conv_Conv2d\n",
            "\t features.22_activation_ReLU\n",
            "\t features.23_pooling_MaxPool2d\n",
            "\t features.24_conv_Conv2d\n",
            "\t features.25_activation_ReLU\n",
            "\t features.26_conv_Conv2d\n",
            "\t features.27_activation_ReLU\n",
            "\t features.28_conv_Conv2d\n",
            "\t features.29_activation_ReLU\n",
            "\t features.30_pooling_MaxPool2d\n",
            "avgpool_pooling_AdaptiveAvgPool2d\n",
            "classifier_container_Sequential\n",
            "\t classifier.0_linear_Linear\n",
            "\t classifier.1_activation_ReLU\n",
            "\t classifier.2_dropout_Dropout\n",
            "\t classifier.3_linear_Linear\n",
            "\t classifier.4_activation_ReLU\n",
            "\t classifier.5_dropout_Dropout\n",
            "\t classifier.6_linear_Linear\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PdjmejRA3dTN"
      },
      "source": [
        "## Create the CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVPyk2bfGfvS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('kitti0001_deepFeaturesDepthless-sensors.csv', 'w', newline='') as myfile:\n",
        "    writer = csv.writer(myfile, quoting=csv.QUOTE_NONNUMERIC, delimiter=',')\n",
        "    writer.writerows(row_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "kernelspec": {
      "name": "tfm",
      "display_name": "TFM"
    },
    "colab": {
      "name": "obtainData_ConvolutionalFeatures.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5bba306fadd24d7cbcf47b85eed56190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a3e2ce67e33042edad7acfe12b56e213",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_63f62925001c41eb9cb7cd245ee6ada6",
              "IPY_MODEL_dc893e72907743fa94d894e3fdbe4082"
            ]
          }
        },
        "a3e2ce67e33042edad7acfe12b56e213": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63f62925001c41eb9cb7cd245ee6ada6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d0a67eeb51314f57a24ab4e193395046",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2e6471f2762a4470b2bcd84a62623cd5"
          }
        },
        "dc893e72907743fa94d894e3fdbe4082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b1107d8d742453ba0cba8585b197618",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [01:59&lt;00:00, 4.64MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9eaedc4a918419ba0918040a26679b4"
          }
        },
        "d0a67eeb51314f57a24ab4e193395046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2e6471f2762a4470b2bcd84a62623cd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b1107d8d742453ba0cba8585b197618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9eaedc4a918419ba0918040a26679b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}