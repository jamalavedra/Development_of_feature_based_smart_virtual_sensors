{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<torch._C.Generator at 0x7ffb50109150>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import torch \n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from ast import literal_eval\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "torch.manual_seed(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "number of frames: 1242\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       x_displacement  y_displacement\ncount     1242.000000     1242.000000\nmean         0.512738       -0.020356\nstd          0.747939        0.643801\nmin         -4.269464       -1.247837\n25%          0.255773       -0.246604\n50%          0.555293       -0.002406\n75%          1.070713        0.125856\nmax          2.550284        7.879498",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x_displacement</th>\n      <th>y_displacement</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1242.000000</td>\n      <td>1242.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.512738</td>\n      <td>-0.020356</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.747939</td>\n      <td>0.643801</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-4.269464</td>\n      <td>-1.247837</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.255773</td>\n      <td>-0.246604</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.555293</td>\n      <td>-0.002406</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.070713</td>\n      <td>0.125856</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.550284</td>\n      <td>7.879498</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# training_set = pd.read_csv('../CSV_files/BALL/dataBall_SIFT-sensors.csv')\n",
    "training_set = pd.read_csv('../CSV_files/KITTI/SIFT/kitti_SIFTDepthless-sensorsALL.csv')\n",
    "dataSet_len = len(training_set)\n",
    "print(f\"number of frames: {dataSet_len}\")\n",
    "featuresAreCoordinates = False\n",
    "training_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_sensorData = [literal_eval(i) for i in training_set['sensors_e']]\n",
    "x_sensorData = [literal_eval(i) for i in training_set['sensors_x']]\n",
    "y_sensorData = [literal_eval(i) for i in training_set['sensors_y']]\n",
    "if featuresAreCoordinates:\n",
    "    coordinates = [literal_eval(i) for i in training_set['coordinates_src']]\n",
    "    coordinatesDST = [literal_eval(i) for i in training_set['coordinates_dst']]\n",
    "    for i in range(len(coordinates)):\n",
    "        coordinates[i].extend(coordinatesDST[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "max amount of sensors: 130\nmin amount of sensors: 130\nmean amount of sensors: 130\n"
    }
   ],
   "source": [
    "numberOfSensorsList = [len(i) for i in distance_sensorData]\n",
    "meanOfSensors = sum(numberOfSensorsList)//len(numberOfSensorsList)\n",
    "maxNumberSensors = max(numberOfSensorsList)\n",
    "minNumberSensors = min(numberOfSensorsList)\n",
    "\n",
    "print(f\"max amount of sensors: {maxNumberSensors}\")\n",
    "print(f\"min amount of sensors: {minNumberSensors}\")\n",
    "print(f\"mean amount of sensors: {meanOfSensors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarizeSensors(list_sensors, threshold):\n",
    "    while len(list_sensors) != threshold:\n",
    "        if len(list_sensors) < threshold:\n",
    "            list_sensors.append(0.0)\n",
    "        elif len(list_sensors) > threshold:\n",
    "            list_sensors = list_sensors[:threshold]\n",
    "    return list_sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim to normalized number of sensors\n",
    "distance_sensorData = [standarizeSensors(i, meanOfSensors) for i in distance_sensorData]\n",
    "x_sensorData = [standarizeSensors(i, meanOfSensors) for i in x_sensorData]\n",
    "y_sensorData = [standarizeSensors(i, meanOfSensors) for i in y_sensorData]\n",
    "if featuresAreCoordinates:\n",
    "    coordinates = [standardizeSensors(i, meanOfSensors*4) for i in coordinates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize feature information\n",
    "scFeatures = MinMaxScaler()\n",
    "distance_sensorData = scFeatures.fit_transform(distance_sensorData)\n",
    "x_sensorData = scFeatures.fit_transform(x_sensorData)\n",
    "y_sensorData = scFeatures.fit_transform(y_sensorData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1242, 3, 130)\n(1242, 390)\n"
    }
   ],
   "source": [
    "coordinates_depth = 4\n",
    "displacement_depth = 3\n",
    "\n",
    "if featuresAreCoordinates:\n",
    "    feature_data = np.array(coordinates)\n",
    "    feature_data = feature_data.reshape(feature_data.shape[0], -1)\n",
    "    print(feature_data.shape)\n",
    "else: \n",
    "    feature_data = []\n",
    "    for i in range(dataSet_len):\n",
    "        feature_data.append([x_sensorData[i], y_sensorData[i], distance_sensorData[i]])\n",
    "    feature_data = np.array(feature_data)\n",
    "    print(feature_data.shape)\n",
    "    feature_data = feature_data.reshape(feature_data.shape[0], -1)\n",
    "    print(feature_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc[row_selection, column_selection]\n",
    "# can be used to separate between feature data and targets\n",
    "# feature data: data we watn to learn from\n",
    "# targets: desired outcome\n",
    "sc = MinMaxScaler()\n",
    "df_target = pd.DataFrame({'x_displacement':target_dataX,'y_displacement':target_dataY})\n",
    "target_data = sc.fit_transform(df_target)\n",
    "\n",
    "plt.plot( target_data, label = 'target volume')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data_reshaped = np.array(target_data)[:, np.newaxis]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_data, target_data, test_size = 0.3, shuffle= True)\n",
    "\n",
    "dataX = torch.Tensor(feature_data)\n",
    "dataY = torch.Tensor(target_data)\n",
    "\n",
    "trainX = torch.Tensor(X_train)\n",
    "trainY = torch.Tensor(y_train)\n",
    "\n",
    "testX = torch.Tensor(X_test)\n",
    "testY = torch.Tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(torch.nn.Module): \n",
    "    def __init__(self, input_dim, output_dim): \n",
    "        super(LinearRegressionModel, self).__init__() \n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim) \n",
    "    def forward(self, x): \n",
    "        y_pred = self.linear(x) \n",
    "        return y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "output_size = 2\n",
    "if featuresAreCoordinates:\n",
    "    input_size = meanOfSensors*coordinates_depth\n",
    "else:\n",
    "    input_size = meanOfSensors*displacement_depth\n",
    "\n",
    "model = LinearRegressionModel(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch: 0, loss: 0.36752\nEpoch: 99, loss: 0.00775\n"
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(epochs): \n",
    "    # Forward pass: Compute predicted y by passing  \n",
    "    # x to the model \n",
    "    output = model(trainX) \n",
    "    # Zero gradients, perform a backward pass,  \n",
    "    optimizer.zero_grad()  \n",
    "    # Compute and print loss \n",
    "    loss = criterion(output, trainY) \n",
    "  \n",
    "    # update the weights. \n",
    "    loss.backward() \n",
    "    optimizer.step() \n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\n",
    "    if epoch == epochs-1:\n",
    "        print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # sets the model to evaluation mode\n",
    "test_predict = model(testX)\n",
    "real_loss = criterion(test_predict, testY)\n",
    "print(f\"Test loss: {real_loss.item()}\")\n",
    "\n",
    "train_predict = model(dataX)\n",
    "data_predict = train_predict.data.numpy()\n",
    "dataY_plot = dataY.data.numpy()\n",
    "\n",
    "\n",
    "# create empty table with 12 fields\n",
    "trainPredict_dataset_like = np.zeros(shape=(len(target_data), 2) )\n",
    "# put the predicted values in the right field\n",
    "trainPredict_dataset_like[:, 0] = data_predict[:,0]\n",
    "# inverse transform and then select the right field\n",
    "data_predict = sc.inverse_transform(trainPredict_dataset_like)[:,0]\n",
    "trainPredict_dataset_like[:, 0] = dataY_plot[:,0]\n",
    "dataY_plot = sc.inverse_transform(trainPredict_dataset_like)[:,0]\n",
    "\n",
    "plt.plot(dataY_plot, label = \"real volume\")\n",
    "plt.plot(data_predict, label = \"predicted volume\")\n",
    "plt.suptitle('Volume Prediction')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving a checkpoint\n",
    "# torch.save(model.state_dict(), 'MODELS/BALL/ball-LinearRegression-SIFTDisplacement.pth')"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "tfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
